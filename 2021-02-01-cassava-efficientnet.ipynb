{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install ../input/timm-packages/timm-0.3.4-py3-none-any.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import timm\nimport pandas as pd\nimport numpy as np\nimport os\nimport torch\nimport cv2\n\nfrom torch.utils.data import Dataset,DataLoader\nfrom tqdm import tqdm\nfrom torchvision.transforms import Normalize, CenterCrop, Resize, Compose, ToTensor, ColorJitter\nfrom PIL import Image\nfrom scipy.stats import mode","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_dir = '/kaggle/input/cassava-leaf-disease-classification/test_images/'\nannotations_path = '/kaggle/input/cassava-leaf-disease-classification/train.csv'\nexists_label = False\n\nmodel_path = '../input/efficientnetb1-8-chk0/checkpoint-0.pth.tar'\nmodel_name = 'efficientnet_b1'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CFG = {\n    'num_classes': 5, \n    'img_size': 512, \n    'inference_bs': 64, \n    'num_workers': 2, \n    'device': 'cuda:0', \n    'tta_steps': 1\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ImageInferenceDataset(Dataset):\n    def __init__(self, root_dir, images_df, transform, exists_label=False):\n        self.images_df = images_df\n        self.transform = transform\n        self.root_dir = root_dir\n        self.exists_label = exists_label\n        \n    def __len__(self):\n        return len(self.images_df)\n    \n    def __getitem__(self, index):\n        img_id = self.images_df.iloc[index]['image_id']\n        data = open(os.path.join(self.root_dir, img_id), 'rb')\n        img = Image.open(data).convert('RGB')\n        \n        if self.transform is not None:\n            img = self.transform(img)\n            \n        if self.exists_label:\n            label = self.images_df.iloc[index]['label']\n            return img, torch.tensor(label, dtype=torch.long)\n        else:\n            return img, torch.tensor(-1, dtype=torch.long)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_inference_transforms():\n    return Compose([\n        Resize(CFG['img_size'] + 50, interpolation=Image.BICUBIC),\n        CenterCrop(CFG['img_size']),\n        ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n        ToTensor(), \n        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), \n        ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if exists_label:\n    images_df = pd.read_csv(annotations_path)\nelse:\n    images_df = pd.DataFrame()\n    images_df['image_id'] = list(os.listdir(dataset_dir))\n\ndataset = ImageInferenceDataset(dataset_dir, images_df, get_inference_transforms(), exists_label=exists_label)\n\ndata_loader = torch.utils.data.DataLoader(\n    dataset, \n    batch_size=CFG['inference_bs'],\n    num_workers=CFG['num_workers'],\n    shuffle=False,\n    pin_memory=False\n)\n\ndevice = torch.device(CFG['device'])\nmodel = timm.create_model(model_name, num_classes=5, checkpoint_path=model_path).to(device)\n\nall_predictions = []\naccuracy = 0.0\ncount = 0\n\nmodel.eval()\nwith torch.no_grad():\n    for _ in range(CFG['tta_steps']):\n        step_predictions = []\n        for batch_idx, (img_data, expected) in enumerate(data_loader):\n            imgs = img_data.to(device).float()\n            logits = model(imgs)\n\n            predictions = torch.softmax(logits, 1).detach().cpu().numpy()\n            labels = np.argmax(predictions, axis=1)\n\n            # Compute accuracy\n            expected = expected.detach().cpu().numpy()\n            accuracy += np.sum(expected == labels)\n            count += expected.shape[0]\n\n            step_predictions += list(labels)\n        \n        all_predictions += [step_predictions]\n        \n\nall_predictions = mode(all_predictions, axis=0)[0][0]\n\n# Display accuracy\nprint(count)\nprint(accuracy / count)\n        \nimages_df['label'] = all_predictions\n# print(images_df)\n        \ndel model\ntorch.cuda.empty_cache()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}